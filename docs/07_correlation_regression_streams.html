<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Bill Perry" />


<title>Data Modification</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Bill Perry</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="https://wlperry.github.io/index.html">Bill's Homepage</a>
</li>
<li>
  <a href="https://wlperry.github.io/2018_stats/index.html">Stats and R Homepage</a>
</li>
<li>
  <a href="about.html">About Bill</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Data Modification</h1>
<h4 class="author">Bill Perry</h4>
<h4 class="date">2018/03/14</h4>

</div>


<div id="correlation-and-regression" class="section level2">
<h2>Correlation and Regression</h2>
<p>##Load libraries We will read in the main files and load the libraries as we have worked with so far.</p>
<pre class="r"><code># One new package for summary stats
# install.packages(&quot;broom&quot;)
# install.packages(&quot;GGally&quot;)
# install.packages(&quot;car&quot;)
# install.packages(&quot;gvlma&quot;)
# install.packages(&quot;corrplot&quot;)
# install.packages(&quot;gvlma&quot;)

# load the libraries each time you restart R
library(tidyverse)
library(readxl)
library(lubridate)
library(scales)
library(skimr)
library(janitor)
library(patchwork)
# library(reshape2)
library(broom)
library(GGally)
library(corrplot)
library(car)
library(gvlma)</code></pre>
<pre class="r"><code># read in the file
iris.df &lt;- read_excel(&quot;data/iris_excel.xlsx&quot;) %&gt;%
  clean_names() %&gt;%
  remove_empty(c(&quot;rows&quot;, &quot;cols&quot;)) 

glimpse(iris.df)</code></pre>
<pre><code>## Observations: 150
## Variables: 5
## $ sepal_length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5…
## $ sepal_width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3…
## $ petal_length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1…
## $ petal_width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0…
## $ species      &lt;chr&gt; &quot;setosa&quot;, &quot;setosa&quot;, &quot;setosa&quot;, &quot;setosa&quot;, &quot;setosa&quot;, &quot;…</code></pre>
<p>##An excellent description of the stats for AOV and regression is here:<br />
<a href="https://www.zoology.ubc.ca/~schluter/R/fit-model/" class="uri">https://www.zoology.ubc.ca/~schluter/R/fit-model/</a></p>
<p>##Summary Statistics for the better look ##So this is a lot different than thinking about data from excel<br />
Lets try to do the summary stats on the data now and see how it differs</p>
<pre class="r"><code># the data you want to look at

skim(iris.df)</code></pre>
<pre><code>## Skim summary statistics
##  n obs: 150 
##  n variables: 5 
## 
## ── Variable type:character ─────────────────
##  variable missing complete   n min max empty n_unique
##   species       0      150 150   6  10     0        3
## 
## ── Variable type:numeric ───────────────────
##      variable missing complete   n mean   sd  p0 p25  p50 p75 p100
##  petal_length       0      150 150 3.76 1.77 1   1.6 4.35 5.1  6.9
##   petal_width       0      150 150 1.2  0.76 0.1 0.3 1.3  1.8  2.5
##  sepal_length       0      150 150 5.84 0.83 4.3 5.1 5.8  6.4  7.9
##   sepal_width       0      150 150 3.06 0.44 2   2.8 3    3.3  4.4
##      hist
##  ▇▁▁▂▅▅▃▁
##  ▇▁▁▅▃▃▂▂
##  ▂▇▅▇▆▅▂▂
##  ▁▂▅▇▃▂▁▁</code></pre>
</div>
<div id="look-at-the-relationships-the-hard-way" class="section level2">
<h2>Look at the relationships the hard way</h2>
<pre class="r"><code>iris.df %&gt;% ggplot(aes(x=species, y=petal_width )) + geom_boxplot()</code></pre>
<p><img src="07_correlation_regression_streams_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="long-to-wide-format" class="section level2">
<h2>Long to Wide format</h2>
<pre class="r"><code># this will add an index to the dataframe so you know what individual is which
iris_long.df &lt;- iris.df %&gt;% 
  # mutate(sample = row_number()) %&gt;% 
  gather(part, measure, -species)</code></pre>
</div>
<div id="outliers" class="section level2">
<h2>Outliers</h2>
<pre class="r"><code># Box Plots of data
iris_long.df %&gt;% 
  ggplot( aes(x = part, y = measure, color = species, fill=species))+
  geom_boxplot(alpha=0.3) </code></pre>
<p><img src="07_correlation_regression_streams_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="test-for-normality-of-data-and-using-the-broom-package" class="section level2">
<h2>Test for normality of data and using the broom package</h2>
<p>So I think this is premature but some people like to test the normality of the data but really you should be assessing the normality of the residuals. But here it goes…</p>
<pre class="r"><code># turn off scientific notaton
options(scipen = 999)
# to turn back on 
#options(scipen = 0)

# Test for normality of each group and store in shapirowilktests
# This uses the broom package to get clean output of the test 
iris_long.df %&gt;% group_by(species, part) %&gt;% do(tidy(shapiro.test(.$measure)))</code></pre>
<pre><code>## # A tibble: 12 x 5
## # Groups:   species, part [12]
##    species    part         statistic     p.value method                    
##    &lt;chr&gt;      &lt;chr&gt;            &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;                     
##  1 setosa     petal_length     0.955 0.0548      Shapiro-Wilk normality te…
##  2 setosa     petal_width      0.800 0.000000866 Shapiro-Wilk normality te…
##  3 setosa     sepal_length     0.978 0.460       Shapiro-Wilk normality te…
##  4 setosa     sepal_width      0.972 0.272       Shapiro-Wilk normality te…
##  5 versicolor petal_length     0.966 0.158       Shapiro-Wilk normality te…
##  6 versicolor petal_width      0.948 0.0273      Shapiro-Wilk normality te…
##  7 versicolor sepal_length     0.978 0.465       Shapiro-Wilk normality te…
##  8 versicolor sepal_width      0.974 0.338       Shapiro-Wilk normality te…
##  9 virginica  petal_length     0.962 0.110       Shapiro-Wilk normality te…
## 10 virginica  petal_width      0.960 0.0870      Shapiro-Wilk normality te…
## 11 virginica  sepal_length     0.971 0.258       Shapiro-Wilk normality te…
## 12 virginica  sepal_width      0.967 0.181       Shapiro-Wilk normality te…</code></pre>
<pre class="r"><code>#You can do this on all variables faster with if there was only one grouping
# tapply(iris_long.df$measure, iris_long.df$species, shapiro.test)</code></pre>
</div>
<div id="correlations-plots" class="section level2">
<h2>Correlations Plots</h2>
<p>This info is from:<br />
<a href="http://stackoverflow.com/questions/29697009/correlation-matrix-plot-with-ggplot2" class="uri">http://stackoverflow.com/questions/29697009/correlation-matrix-plot-with-ggplot2</a><br />
and<br />
<a href="https://www.r-bloggers.com/plot-matrix-with-the-r-package-ggally/" class="uri">https://www.r-bloggers.com/plot-matrix-with-the-r-package-ggally/</a><br />
and<br />
<a href="http://ggobi.github.io/ggally/#canonical_correlation_analysis" class="uri">http://ggobi.github.io/ggally/#canonical_correlation_analysis</a></p>
<pre class="r"><code>iris.df %&gt;% select(sepal_length, sepal_width, petal_length, petal_width) %&gt;%
  ggpairs()</code></pre>
<p><img src="07_correlation_regression_streams_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>##Look at the correlation matrix</p>
<pre class="r"><code># correlation matrix of the data with only the numeric data in a dataframe
# the old way - the same really
# cor(setosa.df[,1:4], method = &quot;pearson&quot;) # , method = c(&quot;pearson&quot;, &quot;kendall&quot;, &quot;spearman&quot;)
# need to only have numeric varaibles
iris.df %&gt;% select(-species) %&gt;% cor() </code></pre>
<pre><code>##              sepal_length sepal_width petal_length petal_width
## sepal_length    1.0000000  -0.1175698    0.8717538   0.8179411
## sepal_width    -0.1175698   1.0000000   -0.4284401  -0.3661259
## petal_length    0.8717538  -0.4284401    1.0000000   0.9628654
## petal_width     0.8179411  -0.3661259    0.9628654   1.0000000</code></pre>
</div>
<div id="correlation-test" class="section level1">
<h1>Correlation test</h1>
<pre class="r"><code>petals.cor &lt;- cor.test(iris.df$petal_length, iris.df$petal_width)

# can see by calling model
petals.cor</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  iris.df$petal_length and iris.df$petal_width
## t = 43.387, df = 148, p-value &lt; 0.00000000000000022
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.9490525 0.9729853
## sample estimates:
##       cor 
## 0.9628654</code></pre>
<pre class="r"><code># other way
cor.test(~ petal_length + petal_width, iris.df)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  petal_length and petal_width
## t = 43.387, df = 148, p-value &lt; 0.00000000000000022
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.9490525 0.9729853
## sample estimates:
##       cor 
## 0.9628654</code></pre>
<pre class="r"><code>str(petals.cor)</code></pre>
<pre><code>## List of 9
##  $ statistic  : Named num 43.4
##   ..- attr(*, &quot;names&quot;)= chr &quot;t&quot;
##  $ parameter  : Named int 148
##   ..- attr(*, &quot;names&quot;)= chr &quot;df&quot;
##  $ p.value    : num 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000468
##  $ estimate   : Named num 0.963
##   ..- attr(*, &quot;names&quot;)= chr &quot;cor&quot;
##  $ null.value : Named num 0
##   ..- attr(*, &quot;names&quot;)= chr &quot;correlation&quot;
##  $ alternative: chr &quot;two.sided&quot;
##  $ method     : chr &quot;Pearson&#39;s product-moment correlation&quot;
##  $ data.name  : chr &quot;iris.df$petal_length and iris.df$petal_width&quot;
##  $ conf.int   : num [1:2] 0.949 0.973
##   ..- attr(*, &quot;conf.level&quot;)= num 0.95
##  - attr(*, &quot;class&quot;)= chr &quot;htest&quot;</code></pre>
<pre class="r"><code># You can extract values from the cor.test() object like this:

petals.cor$estimate</code></pre>
<pre><code>##       cor 
## 0.9628654</code></pre>
<pre class="r"><code>petals.cor$p.value</code></pre>
<pre><code>## [1] 0.00000000000000000000000000000000000000000000000000000000000000000000000000000000000004675004</code></pre>
<pre class="r"><code># This calculates the correlation coefficient and the degrees of freedom
iris.df %&gt;% summarize(petal_cor = cor.test(petal_length, petal_width)$estimate,
                   nuts_df = cor.test(petal_length, petal_width)$parameter,
                   nuts.pvalue = cor.test(petal_length, petal_width)$p.value)</code></pre>
<pre><code>## # A tibble: 1 x 3
##   petal_cor nuts_df nuts.pvalue
##       &lt;dbl&gt;   &lt;int&gt;       &lt;dbl&gt;
## 1     0.963     148    4.68e-86</code></pre>
<pre class="r"><code>iris.df %&gt;%  do(tidy(cor.test(.$petal_length, .$petal_width))) </code></pre>
<pre><code>## # A tibble: 1 x 8
##   estimate statistic  p.value parameter conf.low conf.high method
##      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; 
## 1    0.963      43.4 4.68e-86       148    0.949     0.973 Pears…
## # … with 1 more variable: alternative &lt;chr&gt;</code></pre>
<pre class="r"><code># can be done with grouping variables as well</code></pre>
<p>##Regressions</p>
<p>###Read in files</p>
<pre class="r"><code>stds.df &lt;- read_excel(&quot;data/standards.xlsx&quot;)

glimpse(stds.df)</code></pre>
<pre><code>## Observations: 30
## Variables: 5
## $ replicate &lt;dbl&gt; 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, …
## $ std       &lt;dbl&gt; 0.000, 0.000, 0.005, 0.005, 0.010, 0.010, 0.020, 0.020…
## $ drp       &lt;dbl&gt; 0.000, 0.000, 0.002, 0.006, 0.004, 0.003, 0.006, 0.006…
## $ tp        &lt;dbl&gt; -0.002, -0.002, -0.001, -0.001, 0.000, 0.000, 0.002, 0…
## $ nh4       &lt;dbl&gt; 0.008, 0.008, NA, NA, 0.018, 0.018, 0.020, 0.020, 0.02…</code></pre>
<p>###Stds long</p>
<pre class="r"><code>sts_long.df &lt;- stds.df %&gt;%
  gather(analyte, abs, -replicate, - std)</code></pre>
<p>###Linear Regression<br />
Linear regression models</p>
<pre class="r"><code># Fit our regression model
# regression formula and dataframte

drp.model &lt;- lm(data=stds.df, drp ~ std) 

# Summarize and print the results
summary(drp.model) # show regression coefficients table</code></pre>
<pre><code>## 
## Call:
## lm(formula = drp ~ std, data = stds.df)
## 
## Residuals:
##        Min         1Q     Median         3Q        Max 
## -0.0041414 -0.0008169  0.0000548  0.0001750  0.0036839 
## 
## Coefficients:
##              Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept) 0.0008144  0.0004281   1.902              0.0716 .  
## std         0.3003270  0.0009545 314.640 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.001534 on 20 degrees of freedom
##   (8 observations deleted due to missingness)
## Multiple R-squared:  0.9998, Adjusted R-squared:  0.9998 
## F-statistic: 9.9e+04 on 1 and 20 DF,  p-value: &lt; 0.00000000000000022</code></pre>
<p>###AOV table of regression</p>
<pre class="r"><code>anova(drp.model)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: drp
##           Df   Sum Sq  Mean Sq F value                Pr(&gt;F)    
## std        1 0.232855 0.232855   98998 &lt; 0.00000000000000022 ***
## Residuals 20 0.000047 0.000002                                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># # # # # # # # # # # # # # # # # # 
# TYPE II SUM OF SQUARES
#
#
# # # # # # # # # # # # # # # # # # 
Anova(drp.model, type=&quot;II&quot;)</code></pre>
<pre><code>## Anova Table (Type II tests)
## 
## Response: drp
##             Sum Sq Df F value                Pr(&gt;F)    
## std       0.232855  1   98998 &lt; 0.00000000000000022 ***
## Residuals 0.000047 20                                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># # # # # # # # # # # # # # # # # # 
# TYPE III SUM OF SQUARES
#
## # # # # # # # # # # # # # # # # # 
Anova(drp.model, type=&quot;III&quot;)</code></pre>
<pre><code>## Anova Table (Type III tests)
## 
## Response: drp
##               Sum Sq Df    F value               Pr(&gt;F)    
## (Intercept) 0.000009  1     3.6186              0.07164 .  
## std         0.232855  1 98998.2721 &lt; 0.0000000000000002 ***
## Residuals   0.000047 20                                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># NOTE THERE IS NO DIFFERENCE</code></pre>
<p>###Plot of the Regression {#simple_regplot}</p>
<pre class="r"><code>plot(data=stds.df, drp ~ std, main=&quot;Regression Plot&quot;)
abline(drp.model, col=&quot;red&quot;)</code></pre>
<p><img src="07_correlation_regression_streams_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>###Regression plot with GGPLOT which is a bit nicer in my opinion {#ggplot_regplot}</p>
<pre class="r"><code>ggplot(stds.df, aes(x = std, y = drp)) + 
  geom_smooth(method = &quot;lm&quot;) +
  geom_point()</code></pre>
<pre><code>## Warning: Removed 8 rows containing non-finite values (stat_smooth).</code></pre>
<pre><code>## Warning: Removed 8 rows containing missing values (geom_point).</code></pre>
<p><img src="07_correlation_regression_streams_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>###We can use this to get more information about the model fit</p>
<pre class="r"><code># Confidence intervals for the sepal model
confint(drp.model)</code></pre>
<pre><code>##                     2.5 %      97.5 %
## (Intercept) -0.0000786454 0.001707489
## std          0.2983358854 0.302318032</code></pre>
<p>##Linear Regresson Assumptions<br />
Ordinary least squares regression relies on several assumptions<br />
1. residuals are normally distributed and homoscedastic<br />
2. errors are independent<br />
3. relationships are linear<br />
Investigate these assumptions visually by plotting your model:</p>
<p>###Histogram of residuals</p>
<pre class="r"><code># histogram of residuals
hist(residuals(drp.model))</code></pre>
<p><img src="07_correlation_regression_streams_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>###Diagnostic Plots</p>
<pre class="r"><code>par(mar = c(4, 4, 2, 2), mfrow = c(1, 2)) 
plot(drp.model, which = c(1, 2)) # &quot;which&quot; argument optional</code></pre>
<p><img src="07_correlation_regression_streams_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>###Non‐constant Error Variance or Homoscedasticity</p>
<pre class="r"><code># Evaluate homoscedasticity
# non-constant error variance test
ncvTest(drp.model)</code></pre>
<pre><code>## Non-constant Variance Score Test 
## Variance formula: ~ fitted.values 
## Chisquare = 5.294216, Df = 1, p = 0.021396</code></pre>
<p>###Test for normality of residuals<br />
to confirm the qqplot</p>
<pre class="r"><code>#Test for normality of residuals
shapiro.test(drp.model$res)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  drp.model$res
## W = 0.84232, p-value = 0.00249</code></pre>
<div id="save-residuals-for-further-analyses" class="section level3">
<h3>Save residuals for further analyses</h3>
<pre class="r"><code># # now to put the residuals next to the data and make sure that NAs are included
# Not sure why it has an error but it works.
stds.df$residuals[!is.na(stds.df$std)]&lt;-residuals(lm(data=stds.df, drp ~ std, na.action=na.omit))</code></pre>
<pre><code>## Warning: Unknown or uninitialised column: &#39;residuals&#39;.</code></pre>
<pre><code>## Warning in stds.df$residuals[!is.na(stds.df$std)] &lt;- residuals(lm(data
## = stds.df, : number of items to replace is not a multiple of replacement
## length</code></pre>
<pre class="r"><code>head(stds.df)</code></pre>
<pre><code>## # A tibble: 6 x 6
##   replicate   std   drp     tp    nh4 residuals
##       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;
## 1         1 0     0     -0.002  0.008 -0.000814
## 2         2 0     0     -0.002  0.008 -0.000814
## 3         1 0.005 0.002 -0.001 NA     -0.000316
## 4         2 0.005 0.006 -0.001 NA      0.00368 
## 5         1 0.01  0.004  0      0.018  0.000182
## 6         2 0.01  0.003  0      0.018 -0.000818</code></pre>
<p>###Now to add in the predicted values<br />
you could also do this with a formula from the output of the model</p>
<pre class="r"><code># this produces the fitted values for the model

fitted(drp.model)</code></pre>
<pre><code>##            1            2            3            4            5 
## 0.0008144216 0.0008144216 0.0023160564 0.0023160564 0.0038176911 
##            6            7            8           13           14 
## 0.0038176911 0.0068209607 0.0068209607 0.0158307695 0.0158307695 
##           19           20           21           22           23 
## 0.0308471174 0.0308471174 0.0608798133 0.0608798133 0.1209452050 
##           24           25           26           27           28 
## 0.1209452050 0.1810105967 0.1810105967 0.2410759884 0.2410759884 
##           29           30 
## 0.3011413801 0.3011413801</code></pre>
<p>###Store fitted values in dataframe</p>
<pre class="r"><code># now to see a plot of fitted and observed-----
stds.df$fitted[!is.na(stds.df$std)]&lt;-fitted(lm(data=stds.df, drp ~ std, na.action=na.omit))</code></pre>
<pre><code>## Warning: Unknown or uninitialised column: &#39;fitted&#39;.</code></pre>
<pre><code>## Warning in stds.df$fitted[!is.na(stds.df$std)] &lt;- fitted(lm(data =
## stds.df, : number of items to replace is not a multiple of replacement
## length</code></pre>
<pre class="r"><code>head(stds.df)</code></pre>
<pre><code>## # A tibble: 6 x 7
##   replicate   std   drp     tp    nh4 residuals   fitted
##       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1         1 0     0     -0.002  0.008 -0.000814 0.000814
## 2         2 0     0     -0.002  0.008 -0.000814 0.000814
## 3         1 0.005 0.002 -0.001 NA     -0.000316 0.00232 
## 4         2 0.005 0.006 -0.001 NA      0.00368  0.00232 
## 5         1 0.01  0.004  0      0.018  0.000182 0.00382 
## 6         2 0.01  0.003  0      0.018 -0.000818 0.00382</code></pre>
<pre class="r"><code>ggplot(stds.df)  +
    geom_point(aes(x = std, y = drp), color=&quot;blue&quot;)+
     geom_point(aes(x = std, y = fitted), color=&quot;red&quot;)+
    geom_line(aes(x = std, y = fitted), color=&quot;red&quot;)</code></pre>
<pre><code>## Warning: Removed 8 rows containing missing values (geom_point).</code></pre>
<p><img src="07_correlation_regression_streams_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>##Other packages that do similiar things maybe better.</p>
<p>###The gvlma package can do a lot of this automatically {#gvlma}</p>
<pre class="r"><code> #install.packages(&quot;gvlma&quot;)
# library(gvlma)

# Global test of model assumptions
gvmodel &lt;- gvlma(drp.model)
summary(gvmodel)</code></pre>
<pre><code>## 
## Call:
## lm(formula = drp ~ std, data = stds.df)
## 
## Residuals:
##        Min         1Q     Median         3Q        Max 
## -0.0041414 -0.0008169  0.0000548  0.0001750  0.0036839 
## 
## Coefficients:
##              Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept) 0.0008144  0.0004281   1.902              0.0716 .  
## std         0.3003270  0.0009545 314.640 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.001534 on 20 degrees of freedom
##   (8 observations deleted due to missingness)
## Multiple R-squared:  0.9998, Adjusted R-squared:  0.9998 
## F-statistic: 9.9e+04 on 1 and 20 DF,  p-value: &lt; 0.00000000000000022
## 
## 
## ASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS
## USING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:
## Level of Significance =  0.05 
## 
## Call:
##  gvlma(x = drp.model) 
## 
##                       Value p-value                   Decision
## Global Stat        11.05709 0.02593 Assumptions NOT satisfied!
## Skewness            0.01239 0.91138    Assumptions acceptable.
## Kurtosis            6.20162 0.01276 Assumptions NOT satisfied!
## Link Function       3.00386 0.08307    Assumptions acceptable.
## Heteroscedasticity  1.83923 0.17504    Assumptions acceptable.</code></pre>
<p>##Advanced<br />
This is all secondary and more advanced items that you may or may not wish to deal with.</p>
</div>
<div id="we-can-also-look-to-see-what-is-in-the-model-that-is-stored-as-values" class="section level3">
<h3>We can also look to see what is in the model that is stored as Values</h3>
<pre class="r"><code>class(drp.model)</code></pre>
<pre><code>## [1] &quot;lm&quot;</code></pre>
<pre class="r"><code>names(drp.model)</code></pre>
<pre><code>##  [1] &quot;coefficients&quot;  &quot;residuals&quot;     &quot;effects&quot;       &quot;rank&quot;         
##  [5] &quot;fitted.values&quot; &quot;assign&quot;        &quot;qr&quot;            &quot;df.residual&quot;  
##  [9] &quot;na.action&quot;     &quot;xlevels&quot;       &quot;call&quot;          &quot;terms&quot;        
## [13] &quot;model&quot;</code></pre>
<pre class="r"><code>methods(class = class(drp.model))[1:9]</code></pre>
<pre><code>## [1] &quot;add1.lm&quot;     &quot;alias.lm&quot;    &quot;anova.lm&quot;    &quot;Anova.lm&quot;    &quot;augment.lm&quot; 
## [6] &quot;avPlot.lm&quot;   &quot;Boot.lm&quot;     &quot;bootCase.lm&quot; &quot;boxCox.lm&quot;</code></pre>
<p>The code above came from<br />
<a href="http://tutorials.iq.harvard.edu/R/Rstatistics/Rstatistics.html" class="uri">http://tutorials.iq.harvard.edu/R/Rstatistics/Rstatistics.html</a><br />
there are a lot of good examples of comparing models and a lot more about regression not included here.</p>
<p>###Different code for a QQPlot for normality</p>
<pre class="r"><code>qqPlot(drp.model, main=&quot;QQ Plot&quot;) #qq plot for studentized resid</code></pre>
<p><img src="07_correlation_regression_streams_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<pre><code>## [1]  4 30</code></pre>
<p>###leverage plots</p>
<pre class="r"><code>leveragePlots(drp.model) # leverage plots</code></pre>
<p><img src="07_correlation_regression_streams_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<p>###Assess the role of outliers</p>
<pre class="r"><code># Assessing Outliers
outlierTest(drp.model) # Bonferonni p-value for most extreme obs</code></pre>
<pre><code>##     rstudent unadjusted p-value Bonferroni p
## 30 -4.190688         0.00049574     0.010906</code></pre>
<p>###Examine the influence plot using Cook’s Distance</p>
<pre class="r"><code># Influence Plot
influencePlot(drp.model, id.method=&quot;identify&quot;, main=&quot;Influence Plot&quot;, sub=&quot;Circle
size is proportial to Cook&#39;s Distance&quot; )</code></pre>
<pre><code>## Warning in plot.window(...): &quot;id.method&quot; is not a graphical parameter</code></pre>
<pre><code>## Warning in plot.xy(xy, type, ...): &quot;id.method&quot; is not a graphical parameter</code></pre>
<pre><code>## Warning in axis(side = side, at = at, labels = labels, ...): &quot;id.method&quot; is
## not a graphical parameter

## Warning in axis(side = side, at = at, labels = labels, ...): &quot;id.method&quot; is
## not a graphical parameter</code></pre>
<pre><code>## Warning in box(...): &quot;id.method&quot; is not a graphical parameter</code></pre>
<pre><code>## Warning in title(...): &quot;id.method&quot; is not a graphical parameter</code></pre>
<pre><code>## Warning in plot.xy(xy.coords(x, y), type = type, ...): &quot;id.method&quot; is not a
## graphical parameter</code></pre>
<p><img src="07_correlation_regression_streams_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<pre><code>##       StudRes        Hat      CookD
## 4   2.9387711 0.07681676 0.26002703
## 29  0.6328987 0.24096771 0.06554698
## 30 -4.1906880 0.24096771 1.52489835</code></pre>
<p>###Plot studentized residuals vs. fitted values</p>
<pre class="r"><code># plot studentized residuals vs. fitted values
spreadLevelPlot(drp.model)</code></pre>
<p><img src="07_correlation_regression_streams_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<pre><code>## 
## Suggested power transformation:  1.133278</code></pre>
<p>Non‐independence of Errors</p>
<pre class="r"><code># Test for Autocorrelated Errors
durbinWatsonTest(drp.model)</code></pre>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1      0.02442015      1.572472    0.21
##  Alternative hypothesis: rho != 0</code></pre>
<p>###STANDARDIZED REGRESSION - CONVERTED TO Z SCORES</p>
<pre class="r"><code># # Regression analyses, standardized
drp_z.model &lt;- lm(scale(stds.df$drp) ~ scale(stds.df$std))
summary(drp_z.model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = scale(stds.df$drp) ~ scale(stds.df$std))
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.039325 -0.007757  0.000520  0.001661  0.034981 
## 
## Coefficients:
##                     Estimate Std. Error t value            Pr(&gt;|t|)    
## (Intercept)        -0.180268   0.003157   -57.1 &lt;0.0000000000000002 ***
## scale(stds.df$std)  0.904027   0.002873   314.6 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.01456 on 20 degrees of freedom
##   (8 observations deleted due to missingness)
## Multiple R-squared:  0.9998, Adjusted R-squared:  0.9998 
## F-statistic: 9.9e+04 on 1 and 20 DF,  p-value: &lt; 0.00000000000000022</code></pre>
<pre class="r"><code># # The function fitted returns predicted scores whereas the function resid returns residuals
# # THIS IS HOW TO SAVE THE RESIDUALS INTO THE VARIABLE E FOR EROR
# ex$e &lt;- resid(modelweight_lenght.z)</code></pre>
<p>###Confidence intervals of the standardized regression</p>
<pre class="r"><code>confint(drp_z.model)</code></pre>
<pre><code>##                         2.5 %     97.5 %
## (Intercept)        -0.1868536 -0.1736817
## scale(stds.df$std)  0.8980341  0.9100209</code></pre>
<!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-88373117-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments)};
  gtag('js', new Date());

  gtag('config', 'UA-88373117-4');
</script>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>


</body>
</html>
